{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: DLBDSMTP01 – Project: From Model to Production\n",
    "\n",
    "Task 2: Image classification for a refund department (spotlight: Batch processing)\n",
    "\n",
    "## Steps planned:\n",
    "\n",
    "- explore and cleanup the data\n",
    "- prepare the data for training, validation and final testing\n",
    "- train a simple model, using transfer learning\n",
    "    - using MlFlow for tracking\n",
    "    - make at least 3 different models to simulate a real process of model training exploration\n",
    "- evaluate the models and take the best performing\n",
    "- download and pack the best perofmrin model in an API, using docker for simple and flexible deployment\n",
    "- provide a script, which reads in the data to be processed in batches every night\n",
    "- do a final test on the testing data and evaluate final statistics\n",
    "\n",
    "## First lets look at some data from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# read in the labeled datasets. ignore bad lines as some have 11 isntead of 10 columns and lead to errors\n",
    "# we can ignore them here, as we can spare those few training items\n",
    "data = pd.read_csv(\"./data/fashion-dataset/styles.csv\", on_bad_lines=\"skip\")\n",
    "\n",
    "# print some data out for exploration\n",
    "print(data.shape[0])\n",
    "print(data['subCategory'].unique())\n",
    "print(data['masterCategory'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see if we have torch setup for our GPU\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "- check and prepare the training set into pandas dataframes\n",
    "- make a training and testing split\n",
    "- split some of the testing split for the final batch processing to test it later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# setup my file paths first\n",
    "data_folder = \"data/fashion-dataset/\"\n",
    "styles_file = os.path.join(data_folder, \"styles.csv\")\n",
    "images_folder = os.path.join(data_folder, \"images/\")\n",
    "\n",
    "# Load the dataset, ignore the bad lines\n",
    "styles_df = pd.read_csv(styles_file, sep=',', on_bad_lines='skip')\n",
    "\n",
    "# Filter necessary columns, tho dropped not used columns to save some memory\n",
    "columns_needed = ['id', 'masterCategory']\n",
    "# even if we dont have any n/a columns, we still better keep this routine here\n",
    "styles_df = styles_df[columns_needed].dropna()\n",
    "\n",
    "# define our column for the labels, we can change if we want to use a different one\n",
    "target_column = 'masterCategory'\n",
    "\n",
    "# Add image paths to the DataFrame\n",
    "styles_df['image_path'] = styles_df['id'].astype(str) + \".jpg\"\n",
    "styles_df['image_path'] = styles_df['image_path'].apply(lambda x: os.path.join(images_folder, x))\n",
    "\n",
    "# Check if images exist, filter out missing ones, do security wise, we normally assume the dataset is complete\n",
    "styles_df = styles_df[styles_df['image_path'].apply(os.path.exists)]\n",
    "\n",
    "# Filter out classes with fewer than 2 samples, we need to do, as the splitting require it to be at least 2\n",
    "# we should even filter out more as low amount for data will lead to bad predictions. we will see this in the final statistics for those classes\n",
    "class_counts = styles_df[target_column].value_counts()\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "styles_df = styles_df[styles_df[target_column].isin(valid_classes)]\n",
    "\n",
    "# Split data into train/test sets, do normal setup here\n",
    "train_df, test_df = train_test_split(\n",
    "    styles_df,\n",
    "    test_size=0.2,\n",
    "    stratify=styles_df[target_column],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Further split test set for batch processing testing\n",
    "batch_test_df, test_df = train_test_split(\n",
    "    test_df,\n",
    "    test_size=0.5,\n",
    "    stratify=test_df[target_column],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Save splits for later use\n",
    "train_df.to_csv(os.path.join(data_folder, \"train_split.csv\"), index=False)\n",
    "test_df.to_csv(os.path.join(data_folder, \"test_split.csv\"), index=False)\n",
    "batch_test_df.to_csv(os.path.join(data_folder, \"batch_test_split.csv\"), index=False)\n",
    "\n",
    "# show statistics what is left and how much we have in each\n",
    "print(f\"Training set: {len(train_df)} items\")\n",
    "print(f\"Testing set: {len(test_df)} items\")\n",
    "print(f\"Batch testing set: {len(batch_test_df)} items\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training now the models\n",
    "\n",
    "- including here we log our experiements to mlflow, to select the best one later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "# setup my file paths first, we do already, but if we do in different sessions it help avoid errors\n",
    "data_folder = \"data/fashion-dataset/\"\n",
    "train_file = os.path.join(data_folder, \"train_split.csv\")\n",
    "test_file = os.path.join(data_folder, \"test_split.csv\")\n",
    "\n",
    "# hyperparameter grid for simulated different model trainings\n",
    "# parameters are choosed mostly random at this stage\n",
    "CONFIGURATIONS = [\n",
    "    {\"model_name\": \"resnet18\", \"batch_size\": 32, \"learning_rate\": 0.001, \"epochs\": 5},\n",
    "    {\"model_name\": \"resnet34\", \"batch_size\": 16, \"learning_rate\": 0.0005, \"epochs\": 5},\n",
    "    {\"model_name\": \"resnet50\", \"batch_size\": 32, \"learning_rate\": 0.0001, \"epochs\": 5}\n",
    "]\n",
    "\n",
    "# initialize MLflow for tracking\n",
    "mlflow_uri = \"http://127.0.0.1:5000\"\n",
    "mlflow.set_tracking_uri(mlflow_uri)\n",
    "mlflow.set_experiment(\"Fashion Image Classification\")\n",
    "\n",
    "# setup a class to keep our data for easier access\n",
    "# most functions are self explaning, so no need for comments in it\n",
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        image_path = row['image_path']\n",
    "        label = row['masterCategory']\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# load the training data we prepared in previous step\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_df = pd.read_csv(test_file)\n",
    "\n",
    "# ensure no missing or invalid entries\n",
    "# as we establishes, it should have not such data, but be on save side, if we ever switch sets\n",
    "if train_df['masterCategory'].isnull().any():\n",
    "    train_df = train_df.dropna(subset=['masterCategory'])\n",
    "\n",
    "class_names = train_df['masterCategory'].unique()\n",
    "class_to_idx = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "train_df['label'] = train_df['masterCategory'].map(class_to_idx)\n",
    "\n",
    "# transformations to have a certain dimention and size pattern for the tensors. tensorflow require this\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "\n",
    "# we setup a variable for the device, so we can map the data to be on the same device\n",
    "# otherwise tensorflow throws errors. this should prevent it and make it less error prone\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# training through our varios previous defined setups\n",
    "for config in CONFIGURATIONS:\n",
    "    model_name = config[\"model_name\"]\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    learning_rate = config[\"learning_rate\"]\n",
    "    epochs = config[\"epochs\"]\n",
    "\n",
    "    # prepare the dataset now for the reaining.\n",
    "    train_dataset = FashionDataset(train_df, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # same for our testing data. we don´t need it, as we will get results already from tensorflow, but we re-validate it again on a different set we prepared\n",
    "    test_dataset = FashionDataset(test_df, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # model selection by our setup. if we want use other ones, we need to adjust here and in the configuration\n",
    "    if model_name == \"resnet18\":\n",
    "        model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "    elif model_name == \"resnet34\":\n",
    "        model = models.resnet34(weights='IMAGENET1K_V1')\n",
    "    elif model_name == \"resnet50\":\n",
    "        model = models.resnet50(weights='IMAGENET1K_V1')\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "    \n",
    "    # modify the final layer\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "    # send model to GPU (or if not supported to cpu, but we want the GPU for performance)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # loss and optimizer setup\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # start of the training\n",
    "    with mlflow.start_run():\n",
    "        # log parameters to MlFlow for this model training\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "\n",
    "        # save the labels mapping as an artifact, we need them later in the prediction\n",
    "        labels_path = \"class_to_idx.json\"\n",
    "        with open(labels_path, \"w\") as f:\n",
    "            json.dump(class_to_idx, f)\n",
    "        mlflow.log_artifact(labels_path, artifact_path=\"model_artifacts\")\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "                # ensure labels are mapped and converted to tensors\n",
    "                labels = [class_to_idx[str(label)] for label in labels]\n",
    "                labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "\n",
    "                # ensure both images and labels are tensors before moving to GPU\n",
    "                # if we don´t do this, it can result in the issue that the model we transfer learn is still on the cpu and failing the training\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                # print every 100 batches, so we can see the progression\n",
    "                # this one is long running so some feedback while training is helpful\n",
    "                if batch_idx % 100 == 0:\n",
    "                    print(f\"Epoch [{epoch+1}/{epochs}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "            epoch_loss = running_loss / len(train_loader.dataset)\n",
    "            epoch_acc = correct / total\n",
    "\n",
    "            # log updated metrics to the model in MlFlow for later evaluataion\n",
    "            mlflow.log_metric(\"loss\", epoch_loss, step=epoch)\n",
    "            mlflow.log_metric(\"accuracy\", epoch_acc, step=epoch)\n",
    "\n",
    "            print(f\"Model: {model_name}, Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "            # evaluate on the test set after each epoch, we have already the model reported ones, but we want an individual one on top\n",
    "            model.eval()\n",
    "            test_correct = 0\n",
    "            test_total = 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in test_loader:\n",
    "                    labels = [class_to_idx[str(label)] for label in labels]\n",
    "                    labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    outputs = model(images)\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    test_total += labels.size(0)\n",
    "                    test_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            test_acc = test_correct / test_total\n",
    "            mlflow.log_metric(\"test_accuracy\", test_acc, step=epoch)\n",
    "\n",
    "            print(f\"Test Accuracy after Epoch {epoch+1}: {test_acc:.4f}\")\n",
    "\n",
    "\n",
    "            # log model\n",
    "            mlflow.pytorch.log_model(model, \"model\")\n",
    "\n",
    "print(\"Training complete. All models logged to MLflow.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the best model\n",
    "\n",
    "To do so, please go to the MlFlow UI and select the model by the best performance metric. \n",
    "\n",
    "For this training setup it was the resnet 50 model with an overwhelming accuracy. We regsitered the model under the name\n",
    "\n",
    "`fashion-data-model`\n",
    "\n",
    "## Download the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import logging\n",
    "from mlflow.artifacts import download_artifacts\n",
    "\n",
    "# model to fetch and saving folder\n",
    "model_name = \"fashion-data-model\"  \n",
    "output_dir = \"./model_artifacts\"\n",
    "\n",
    "# establish connection to MlFlow, where we want to download the model\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# fetch the latest registered model version\n",
    "# there may better ways, like tags and versions too. in this project this is sufficient to get what we need\n",
    "# adjustements may needed on this part in bigger or progressing projects\n",
    "client = mlflow.MlflowClient()\n",
    "logging.info(f\"Fetching latest registered version of model '{model_name}'...\")\n",
    "registered_model = client.search_model_versions(f\"name='{model_name}'\")\n",
    "\n",
    "if not registered_model:\n",
    "    raise ValueError(f\"No model versions found for '{model_name}'.\")\n",
    "\n",
    "# get the latest version based on creation timestamp\n",
    "latest_version = max(registered_model, key=lambda x: x.creation_timestamp)\n",
    "run_id = latest_version.run_id\n",
    "logging.info(f\"Latest model version: {latest_version.version}, Run ID: {run_id}\")\n",
    "\n",
    "# download the model artifact\n",
    "logging.info(\"Downloading model artifact...\")\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model_path = download_artifacts(artifact_uri=model_uri, dst_path=output_dir)\n",
    "logging.info(f\"Model downloaded to: {model_path}\")\n",
    "\n",
    "# download the labels artifact\n",
    "logging.info(\"Downloading labels artifact...\")\n",
    "labels_uri = f\"runs:/{run_id}/model_artifacts\"\n",
    "labels_path = download_artifacts(artifact_uri=labels_uri, dst_path=output_dir)\n",
    "logging.info(f\"Labels downloaded to: {labels_path}\")\n",
    "\n",
    "logging.info(\"All artifacts downloaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the dockerfile\n",
    "\n",
    "*Ports and namings can be edited to match your local system*\n",
    "\n",
    "in shell: \n",
    "`docker build --no-cache -t model-api-gpu .`\n",
    "\n",
    "## Run the docker container\n",
    "\n",
    "in shell: \n",
    "`docker run --gpus all -p 5001:5001 model-api-gpu`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the images for the final test after the container running\n",
    "\n",
    "For the final evaluation we will copy all images we have in the split of the validation set for the final evaluation.\n",
    "We need to copy them here to the folder so we can test the setup\n",
    "\n",
    "*alternatively the batch run can be packed also in a docker file and run from there, where we copy the images too*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# load the CSV file and setup the folders\n",
    "data_folder = \"data/fashion-dataset/\"\n",
    "batch_file = os.path.join(data_folder, \"batch_test_split.csv\")\n",
    "images_folder = os.path.join(data_folder, \"images/\")\n",
    "\n",
    "df = pd.read_csv(batch_file)\n",
    "\n",
    "# create the 'batch_images' folder if it doesn't exist, we will save the images here\n",
    "output_folder = 'batch_images'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# iterate over each row in the CSV and copy the image\n",
    "for index, row in df.iterrows():\n",
    "    image_path = row['image_path']\n",
    "    if os.path.exists(image_path):\n",
    "        # get the image filename and create the new path\n",
    "        filename = os.path.basename(image_path)\n",
    "        new_path = os.path.join(output_folder, filename)\n",
    "        \n",
    "        # copy the image to the new folder\n",
    "        shutil.copy(image_path, new_path)\n",
    "        print(f'Copied {image_path} to {new_path}')\n",
    "    else:\n",
    "        print(f'Image not found: {image_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the script and code\n",
    "\n",
    "in shell:\n",
    "`py batch_processing.py`\n",
    "\n",
    "This will let the results be processed locally and also test the API in docker already. as mentioned alternatively the whole script and files could be packed and run as a cron already in a Docker container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the final run\n",
    "\n",
    "*if used a different setup and not run the processing locally ones for testing, please adjust and copy the files to match it here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# initiate the files and labels we need for a final evaluation. \n",
    "# mind that a batch must have run and files are copied in the correct place\n",
    "GROUND_TRUTH_CSV = \"data/fashion-dataset/styles.csv\"  # path to the ground truth styles CSV, our original file with the correct labels\n",
    "PREDICTIONS_CSV = \"output/predictions.csv\"  # ath to predictions CSV, that it the file we generated with the output of a batch\n",
    "TARGET_COLUMN = \"masterCategory\"  # Column to evaluate the label, should match what we used in the first steps when preparing the data and training the model\n",
    "\n",
    "def create_evaluation_visualizations(y_true, y_pred, output_dir=\"output\"):\n",
    "    \"\"\"\n",
    "    Create and save visualization charts for model evaluation results. It will create a graph from the data comparison and save it in the same folder as the predicted csv file is, if not provide an own folder\n",
    "    \n",
    "    Args:\n",
    "        y_true: Array-like of true labels\n",
    "        y_pred: Array-like of predicted labels\n",
    "        output_dir: Directory to save the plots\n",
    "    \"\"\"\n",
    "    # set style, better would be seaborn, but somehow it not accept the style, so we use the default one and setup some more styles on the elements later to make it better\n",
    "    plt.style.use('default')\n",
    "    \n",
    "    # create figure with multiple subplots\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    gs = fig.add_gridspec(2, 2)\n",
    "    \n",
    "    # cnfusion matrix heatmap\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1)\n",
    "    ax1.set_title('Confusion Matrix')\n",
    "    ax1.set_xlabel('Predicted')\n",
    "    ax1.set_ylabel('True')\n",
    "    \n",
    "    # class distribution comparison\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    df_comparison = pd.DataFrame({\n",
    "        'True': pd.Series(y_true).value_counts(),\n",
    "        'Predicted': pd.Series(y_pred).value_counts()\n",
    "    }).fillna(0)\n",
    "    df_comparison.plot(kind='bar', ax=ax2)\n",
    "    ax2.set_title('Class Distribution: True vs Predicted', pad=15)\n",
    "    ax2.set_xlabel('Classes')\n",
    "    ax2.set_ylabel('Count')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # accuracy by class\n",
    "    ax3 = fig.add_subplot(gs[1, :])\n",
    "    class_accuracy = {}\n",
    "    for class_name in set(y_true):\n",
    "        mask = y_true == class_name\n",
    "        class_accuracy[class_name] = accuracy_score(y_true[mask], y_pred[mask])\n",
    "    \n",
    "    accuracy_df = pd.DataFrame.from_dict(class_accuracy, orient='index', \n",
    "                                       columns=['Accuracy'])\n",
    "    accuracy_df.sort_values('Accuracy', ascending=True).plot(\n",
    "        kind='barh', ax=ax3)\n",
    "    ax3.set_title('Accuracy by Class')\n",
    "    ax3.set_xlabel('Accuracy')\n",
    "    \n",
    "    # adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/evaluation_visualization.png\", \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def evaluate_predictions(ground_truth_csv, predictions_csv, target_column):\n",
    "    \"\"\"\n",
    "    simply compare the predictions from the pre-labeled file with the predicitons from the batch results. Using only images from the output \n",
    "    file, so we compare only the ones we let run and not all to get correct data\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # load ground truth and predictions\n",
    "        ground_truth = pd.read_csv(ground_truth_csv, sep=',', on_bad_lines='skip')\n",
    "        predictions = pd.read_csv(predictions_csv)\n",
    "        \n",
    "        # ensure predictions file has required columns\n",
    "        # it should have, but be save we check it again\n",
    "        if 'filename' not in predictions or 'prediction' not in predictions:\n",
    "            raise ValueError(\"Predictions file must contain 'filename' and 'prediction' columns.\")\n",
    "        \n",
    "        # extract IDs from the prediction filenames\n",
    "        predictions['id'] = predictions['filename'].str.replace(\".jpg\", \"\", regex=False).astype(int)\n",
    "        \n",
    "        # filter ground truth to only include IDs present in predictions\n",
    "        ground_truth_filtered = ground_truth[ground_truth['id'].isin(predictions['id'])]\n",
    "        \n",
    "        # merge ground truth and predictions on 'id'\n",
    "        merged_df = pd.merge(ground_truth_filtered, predictions, on=\"id\", how=\"inner\")\n",
    "        \n",
    "        # Check for unmatched IDs and report if we dont have an ID in both CSVs. Should not happen, but better is better\n",
    "        unmatched_count = len(predictions) - len(merged_df)\n",
    "        if unmatched_count > 0:\n",
    "            print(f\"Warning: {unmatched_count} predictions have no matching ground truth.\")\n",
    "        \n",
    "        # extract true labels and predictions\n",
    "        y_true = merged_df[target_column]\n",
    "        y_pred = merged_df['prediction']\n",
    "        \n",
    "        # calculate metrics\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        report = classification_report(y_true, y_pred, output_dict=False)\n",
    "        \n",
    "        # create visualizations\n",
    "        create_evaluation_visualizations(y_true, y_pred)\n",
    "        \n",
    "        # print evaluation metrics\n",
    "        print(f\"Accuracy: {accuracy:.2%}\")\n",
    "        print(\"\\nClassification Report:\\n\", report)\n",
    "        \n",
    "        # save detailed evaluation results\n",
    "        merged_df['correct'] = merged_df[target_column] == merged_df['prediction']\n",
    "        output_file = \"output/evaluation_results.csv\" #again we save to the output here. if needed can be adjusted or in future need to make one static folder variable at the top\n",
    "        merged_df.to_csv(output_file, index=False)\n",
    "        print(f\"Detailed evaluation results saved to: {output_file}\")\n",
    "        print(\"Visualization plots saved to: output/evaluation_visualization.png\")\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Could not find input file - {e}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(\"Error: One of the input files is empty\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during evaluation: {str(e)}\")\n",
    "\n",
    "# run evaluation\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_predictions(GROUND_TRUTH_CSV, PREDICTIONS_CSV, TARGET_COLUMN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment of the batch\n",
    "\n",
    "**2 ways here:**\n",
    "\n",
    "1. copy the file on a server of choice and setup the crontab\n",
    "\n",
    "2. create a Docker container and setup all there. Let a process copy the files into the folder for processing on the container\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "> Suggested crontab entry\n",
    "\n",
    "`5 0 * * * /usr/bin/python3 /opt/scripts/batch_processing.py`\n",
    "\n",
    "*Don´t forget to grant the correct file access permissions for the user running it*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_test-rJK-ShzJ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
